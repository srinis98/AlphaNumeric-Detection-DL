{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Task 2\n",
    "A simple model to classify 47 categories of handwritten alpha-numeric charecters, is defined in this notebook.\n",
    "Class-wise classification report has been generated using sklearn.\n",
    "\n",
    "The following sources were referenced:\n",
    "1. https://stackoverflow.com/questions/16992713/translate-every-element-in-numpy-array-according-to-key\n",
    "2. https://stackoverflow.com/questions/45930750/how-to-output-per-class-accuracy-in-keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO : Function to read dataframe and return the images and lables array generated\n",
    "\n",
    "def images_labels(data_df):\n",
    "    labels = data_df.iloc[:,0].values\n",
    "    images = data_df.iloc[:,1:].values.reshape(len(data_df),28,28,1,order='F') ## column major ordering\n",
    "    images = images/255.0\n",
    "    return labels,images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the test, train and validation sets\n",
    "\n",
    "DATASET_PATH = r'.\\Character + Digits data\\\\'\n",
    "\n",
    "test_data = pd.read_csv(DATASET_PATH+'characters-digits-test.csv',header=None)\n",
    "test_labels,test_images = images_labels(test_data)\n",
    "\n",
    "train_dataSet = pd.read_csv(DATASET_PATH+'characters-digits-train.csv',header=None)\n",
    "train_df, val_df = train_test_split(train_dataSet, test_size=0.2)\n",
    "\n",
    "train_labels, train_images = images_labels(train_df)\n",
    "val_labels, val_images = images_labels(val_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train : ((90240,), (90240, 28, 28, 1))\n",
      "validation : ((22560,), (22560, 28, 28, 1))\n",
      "test : ((18800,), (18800, 28, 28, 1)) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## checking the test, train and validation arrays\n",
    "\n",
    "print('train :' ,(train_labels.shape, train_images.shape))\n",
    "print('validation :' ,(val_labels.shape, val_images.shape))\n",
    "print('test :' ,(test_labels.shape, test_images.shape),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO : Define the model \n",
    "# defining early stopping based on validation accuracy\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy', \n",
    "    verbose=1,\n",
    "    patience=5,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90240 samples, validate on 22560 samples\n",
      "Epoch 1/25\n",
      "90240/90240 [==============================] - 76s 845us/sample - loss: 1.2786 - accuracy: 0.6246 - val_loss: 0.5393 - val_accuracy: 0.8213\n",
      "Epoch 2/25\n",
      "90240/90240 [==============================] - 76s 842us/sample - loss: 0.6776 - accuracy: 0.7832 - val_loss: 0.4402 - val_accuracy: 0.8509\n",
      "Epoch 3/25\n",
      "90240/90240 [==============================] - 76s 842us/sample - loss: 0.5713 - accuracy: 0.8150 - val_loss: 0.4014 - val_accuracy: 0.8629\n",
      "Epoch 4/25\n",
      "90240/90240 [==============================] - 75s 833us/sample - loss: 0.5131 - accuracy: 0.8311 - val_loss: 0.3879 - val_accuracy: 0.8645\n",
      "Epoch 5/25\n",
      "90240/90240 [==============================] - 75s 833us/sample - loss: 0.4825 - accuracy: 0.8407 - val_loss: 0.3807 - val_accuracy: 0.8701\n",
      "Epoch 6/25\n",
      "90240/90240 [==============================] - 75s 835us/sample - loss: 0.4635 - accuracy: 0.8479 - val_loss: 0.3704 - val_accuracy: 0.8750\n",
      "Epoch 7/25\n",
      "90240/90240 [==============================] - 75s 833us/sample - loss: 0.4556 - accuracy: 0.8505 - val_loss: 0.3708 - val_accuracy: 0.8752\n",
      "Epoch 8/25\n",
      "90240/90240 [==============================] - 75s 830us/sample - loss: 0.4526 - accuracy: 0.8527 - val_loss: 0.4056 - val_accuracy: 0.8722\n",
      "Epoch 9/25\n",
      "90240/90240 [==============================] - 75s 832us/sample - loss: 0.4454 - accuracy: 0.8547 - val_loss: 0.3878 - val_accuracy: 0.8741\n",
      "Epoch 10/25\n",
      "90240/90240 [==============================] - 76s 838us/sample - loss: 0.4473 - accuracy: 0.8545 - val_loss: 0.3682 - val_accuracy: 0.8766\n",
      "Epoch 11/25\n",
      "90240/90240 [==============================] - 76s 843us/sample - loss: 0.4454 - accuracy: 0.8554 - val_loss: 0.3783 - val_accuracy: 0.8774\n",
      "Epoch 12/25\n",
      "90240/90240 [==============================] - 75s 829us/sample - loss: 0.4431 - accuracy: 0.8561 - val_loss: 0.3625 - val_accuracy: 0.8744\n",
      "Epoch 13/25\n",
      "90240/90240 [==============================] - 75s 833us/sample - loss: 0.4440 - accuracy: 0.8566 - val_loss: 0.3589 - val_accuracy: 0.8781\n",
      "Epoch 14/25\n",
      "90240/90240 [==============================] - 75s 830us/sample - loss: 0.4426 - accuracy: 0.8571 - val_loss: 0.3686 - val_accuracy: 0.8772\n",
      "Epoch 15/25\n",
      "90240/90240 [==============================] - 75s 832us/sample - loss: 0.4463 - accuracy: 0.8562 - val_loss: 0.4079 - val_accuracy: 0.8727\n",
      "Epoch 16/25\n",
      "90240/90240 [==============================] - 75s 833us/sample - loss: 0.4430 - accuracy: 0.8570 - val_loss: 0.3835 - val_accuracy: 0.8766\n",
      "Epoch 17/25\n",
      "90240/90240 [==============================] - 75s 835us/sample - loss: 0.4451 - accuracy: 0.8566 - val_loss: 0.3742 - val_accuracy: 0.8757\n",
      "Epoch 18/25\n",
      "90112/90240 [============================>.] - ETA: 0s - loss: 0.4424 - accuracy: 0.8577Restoring model weights from the end of the best epoch.\n",
      "90240/90240 [==============================] - 76s 839us/sample - loss: 0.4429 - accuracy: 0.8577 - val_loss: 0.5504 - val_accuracy: 0.8575\n",
      "Epoch 00018: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cf31684f48>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the CNN model \n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.Dense(47, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.summary()\n",
    "model.fit(train_images, train_labels, \n",
    "          epochs=25,\n",
    "          batch_size = 128,\n",
    "          callbacks = [early_stopping],\n",
    "          validation_data=(val_images, val_labels)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the model. \n",
    "model.save(\"task2_v1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18800/18800 [==============================] - 6s 325us/sample - loss: 0.3881 - accuracy: 0.8728\n",
      "[0.38805885689055664, 0.8728191]\n"
     ]
    }
   ],
   "source": [
    "test_loss = model.evaluate(test_images, test_labels)\n",
    "print(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO : generate the classwise accuracy\n",
    "# map the data to ascii values to get the right labels\n",
    "# https://stackoverflow.com/questions/16992713/translate-every-element-in-numpy-array-according-to-key\n",
    "\n",
    "mapping_df = pd.read_csv(DATASET_PATH+'characters-digits-mapping.txt',header=None,delimiter = ' ')\n",
    "mapping_df['class_name'] = mapping_df[1].apply(chr)\n",
    "mapping_dict = dict(zip(mapping_df[0], mapping_df.class_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.639560</td>\n",
       "      <td>0.727500</td>\n",
       "      <td>0.680702</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.504039</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.612365</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.919060</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.899106</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.987374</td>\n",
       "      <td>0.977500</td>\n",
       "      <td>0.982412</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.885442</td>\n",
       "      <td>0.927500</td>\n",
       "      <td>0.905983</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.938830</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.909794</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.950649</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.932484</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.956098</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.967901</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.919118</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.928218</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.641618</td>\n",
       "      <td>0.832500</td>\n",
       "      <td>0.724701</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.933014</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.953545</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.972362</td>\n",
       "      <td>0.967500</td>\n",
       "      <td>0.969925</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.954315</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.947103</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.928947</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.905128</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.989717</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.975919</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.675393</td>\n",
       "      <td>0.645000</td>\n",
       "      <td>0.659847</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.929268</td>\n",
       "      <td>0.952500</td>\n",
       "      <td>0.940741</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.953202</td>\n",
       "      <td>0.967500</td>\n",
       "      <td>0.960298</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.674095</td>\n",
       "      <td>0.605000</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.936548</td>\n",
       "      <td>0.922500</td>\n",
       "      <td>0.929471</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.984334</td>\n",
       "      <td>0.942500</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.698113</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.483660</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.962594</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>0.963795</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.928401</td>\n",
       "      <td>0.972500</td>\n",
       "      <td>0.949939</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.682864</td>\n",
       "      <td>0.667500</td>\n",
       "      <td>0.675095</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.934146</td>\n",
       "      <td>0.957500</td>\n",
       "      <td>0.945679</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.922500</td>\n",
       "      <td>0.927136</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.955000</td>\n",
       "      <td>0.955000</td>\n",
       "      <td>0.955000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.867133</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.897467</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.928934</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.921914</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>0.917275</td>\n",
       "      <td>0.942500</td>\n",
       "      <td>0.929716</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>0.939314</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.913992</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>0.982500</td>\n",
       "      <td>0.982500</td>\n",
       "      <td>0.982500</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>0.966495</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.951777</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>0.901554</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.885496</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>0.893112</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.915956</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>0.860241</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>0.876074</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>0.896882</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.915545</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>0.969773</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.966123</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>0.967254</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.963614</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>0.649383</td>\n",
       "      <td>0.657500</td>\n",
       "      <td>0.653416</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>0.701087</td>\n",
       "      <td>0.645000</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>0.929648</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.927318</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>0.707224</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>0.561086</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>0.889930</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.918984</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>0.905852</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.897856</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.872819</td>\n",
       "      <td>0.872819</td>\n",
       "      <td>0.872819</td>\n",
       "      <td>0.872819</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.875734</td>\n",
       "      <td>0.872819</td>\n",
       "      <td>0.871432</td>\n",
       "      <td>18800.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>0.875734</td>\n",
       "      <td>0.872819</td>\n",
       "      <td>0.871432</td>\n",
       "      <td>18800.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           index  precision    recall  f1-score       support class_label\n",
       "0              0   0.639560  0.727500  0.680702    400.000000           0\n",
       "1              1   0.504039  0.780000  0.612365    400.000000           1\n",
       "2              2   0.919060  0.880000  0.899106    400.000000           2\n",
       "3              3   0.987374  0.977500  0.982412    400.000000           3\n",
       "4              4   0.885442  0.927500  0.905983    400.000000           4\n",
       "5              5   0.938830  0.882500  0.909794    400.000000           5\n",
       "6              6   0.950649  0.915000  0.932484    400.000000           6\n",
       "7              7   0.956098  0.980000  0.967901    400.000000           7\n",
       "8              8   0.919118  0.937500  0.928218    400.000000           8\n",
       "9              9   0.641618  0.832500  0.724701    400.000000           9\n",
       "10            10   0.933014  0.975000  0.953545    400.000000           A\n",
       "11            11   0.972362  0.967500  0.969925    400.000000           B\n",
       "12            12   0.954315  0.940000  0.947103    400.000000           C\n",
       "13            13   0.928947  0.882500  0.905128    400.000000           D\n",
       "14            14   0.989717  0.962500  0.975919    400.000000           E\n",
       "15            15   0.675393  0.645000  0.659847    400.000000           F\n",
       "16            16   0.929268  0.952500  0.940741    400.000000           G\n",
       "17            17   0.953202  0.967500  0.960298    400.000000           H\n",
       "18            18   0.674095  0.605000  0.637681    400.000000           I\n",
       "19            19   0.936548  0.922500  0.929471    400.000000           J\n",
       "20            20   0.984334  0.942500  0.962963    400.000000           K\n",
       "21            21   0.698113  0.370000  0.483660    400.000000           L\n",
       "22            22   0.962594  0.965000  0.963795    400.000000           M\n",
       "23            23   0.928401  0.972500  0.949939    400.000000           N\n",
       "24            24   0.682864  0.667500  0.675095    400.000000           O\n",
       "25            25   0.934146  0.957500  0.945679    400.000000           P\n",
       "26            26   0.931818  0.922500  0.927136    400.000000           Q\n",
       "27            27   0.955000  0.955000  0.955000    400.000000           R\n",
       "28            28   0.867133  0.930000  0.897467    400.000000           S\n",
       "29            29   0.928934  0.915000  0.921914    400.000000           T\n",
       "30            30   0.917275  0.942500  0.929716    400.000000           U\n",
       "31            31   0.939314  0.890000  0.913992    400.000000           V\n",
       "32            32   0.982500  0.982500  0.982500    400.000000           W\n",
       "33            33   0.966495  0.937500  0.951777    400.000000           X\n",
       "34            34   0.901554  0.870000  0.885496    400.000000           Y\n",
       "35            35   0.893112  0.940000  0.915956    400.000000           Z\n",
       "36            36   0.860241  0.892500  0.876074    400.000000           a\n",
       "37            37   0.896882  0.935000  0.915545    400.000000           b\n",
       "38            38   0.969773  0.962500  0.966123    400.000000           d\n",
       "39            39   0.967254  0.960000  0.963614    400.000000           e\n",
       "40            40   0.649383  0.657500  0.653416    400.000000           f\n",
       "41            41   0.701087  0.645000  0.671875    400.000000           g\n",
       "42            42   0.929648  0.925000  0.927318    400.000000           h\n",
       "43            43   0.920000  0.920000  0.920000    400.000000           n\n",
       "44            44   0.707224  0.465000  0.561086    400.000000           q\n",
       "45            45   0.889930  0.950000  0.918984    400.000000           r\n",
       "46            46   0.905852  0.890000  0.897856    400.000000           t\n",
       "47      accuracy   0.872819  0.872819  0.872819      0.872819         NaN\n",
       "48     macro avg   0.875734  0.872819  0.871432  18800.000000         NaN\n",
       "49  weighted avg   0.875734  0.872819  0.871432  18800.000000         NaN"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## https://stackoverflow.com/questions/45930750/how-to-output-per-class-accuracy-in-keras\n",
    "\n",
    "pred_labels = model.predict_classes(test_images)\n",
    "report_dict = classification_report(test_labels, pred_labels,output_dict=True)\n",
    "report_df = pd.DataFrame(report_dict).transpose()\n",
    "report_df = report_df.reset_index()\n",
    "report_df['class_label'] = report_df.loc[0:46,'index'].astype('int').replace(mapping_dict)\n",
    "report_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
